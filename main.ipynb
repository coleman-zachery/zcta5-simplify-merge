{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "%pip install -q fiona folium geopandas numpy pandas python-dotenv requests shapely\n",
    "\n",
    "# third-party\n",
    "import fiona\n",
    "import folium\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import requests\n",
    "from shapely import make_valid, MultiPolygon, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "\n",
    "# standard\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get Raw Zipcode Files\n",
    "    - Download most recent data from census.gov\n",
    "    - Unzip downloaded file\n",
    "    - Make raw zipcodes directory\n",
    "    - Write raw zipcode files using unzipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "CENSUS_URL = 'https://www2.census.gov/geo/tiger/TIGER'\n",
    "MB = 1 << 20\n",
    "DOWNLOADS_DIRPATH = 'downloads/'\n",
    "RAW_ZIPCODES_DIRPATH = 'raw_zipcodes/'\n",
    "ZIPCODES_DIRPATH = 'Zipcodes/'\n",
    "RAW_JSON_EXT = '_raw.json'\n",
    "\n",
    "# helpers\n",
    "def get_download_url():\n",
    "    for YEAR in range((y := datetime.now().year), y - 20, -1):\n",
    "        zip_url = f'{CENSUS_URL}{YEAR}/'\n",
    "        response = requests.get(zip_url, stream=True)\n",
    "        if response.status_code != 200: continue\n",
    "        i = response.text.find('ZCTA5')\n",
    "        j = response.text.find('/', i)\n",
    "        ZCTA5 = response.text[i:j]\n",
    "        download_url = f'{CENSUS_URL}{YEAR}/{ZCTA5}/tl_{YEAR}_us_{ZCTA5.lower()}.zip'\n",
    "        return download_url\n",
    "    else:\n",
    "        raise Exception('no good response')\n",
    "\n",
    "def progress_bar(count, total, tag='', normalize=None, length=32):\n",
    "    quotient = count / total\n",
    "    percent = f'{quotient * 100:.1f}%'\n",
    "    progress = f'[{(int(quotient * length) * '=')[:length].ljust(length, '_')}]'\n",
    "    counter = f'({tag} {total} | {count})' if normalize == None else f'({tag} {total / normalize:.1f} | {count / normalize:.1f})'\n",
    "    return f'{percent} {progress} {counter}'\n",
    "\n",
    "def download_zip_file(download_url):\n",
    "    try:\n",
    "        zip_filename = os.path.basename(download_url)\n",
    "        zip_filepath = os.path.join(DOWNLOADS_DIRPATH, zip_filename)\n",
    "        if os.path.exists(zip_filepath):\n",
    "            print(f'zip file already downloaded: {zip_filepath}')\n",
    "            return zip_filepath\n",
    "        os.makedirs(DOWNLOADS_DIRPATH, exist_ok=True)\n",
    "        response = requests.get(download_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        DOWNLOADED = 0\n",
    "        DOWNLOAD_SIZE = int(response.headers.get('content-length', 0))\n",
    "        with open(zip_filepath, 'wb') as FILE:\n",
    "            for CHUNK in response.iter_content(chunk_size=MB):\n",
    "                if not CHUNK: continue\n",
    "                FILE.write(CHUNK)\n",
    "                DOWNLOADED += len(CHUNK)\n",
    "                PROGRESS_BAR = progress_bar(DOWNLOADED, DOWNLOAD_SIZE, 'MB', MB)\n",
    "                print(f'\\rDownloading `{zip_filename}`: {PROGRESS_BAR}', end='')\n",
    "        print(f'\\n`{zip_filename}` downloaded successfully.')\n",
    "        return zip_filepath\n",
    "    except requests.exceptions.RequestException as error:\n",
    "        print(error)\n",
    "\n",
    "def unzip_downloaded_file(zip_filepath):\n",
    "    shape_filepath = zip_filepath.replace('.zip', '.shp')\n",
    "    if os.path.exists(shape_filepath):\n",
    "        print(f'shape file already unzipped: {shape_filepath}')\n",
    "        return None\n",
    "    with ZipFile(zip_filepath, 'r') as FILE:\n",
    "        FILE.extractall(DOWNLOADS_DIRPATH)\n",
    "\n",
    "def count_files(dirpath):\n",
    "    return sum(len(files) for _, _, files in os.walk(dirpath))\n",
    "\n",
    "def make_zipcode_directory(dirpath):\n",
    "    os.makedirs(dirpath, exist_ok=True)\n",
    "    for NUM in range(500, 99999, 500):\n",
    "        sub_dirpath = os.path.join(dirpath, f'{NUM:05}-{NUM+499:05}')\n",
    "        os.makedirs(sub_dirpath, exist_ok=True)\n",
    "\n",
    "def get_zipcode_filepath(zipcode_filename):\n",
    "    dirpath = RAW_ZIPCODES_DIRPATH if zipcode_filename.endswith(RAW_JSON_EXT) else ZIPCODES_DIRPATH\n",
    "    floor = (int(zipcode_filename[:5]) // 500) * 500\n",
    "    return os.path.join(dirpath, f'{floor:05d}-{floor+499:05d}', zipcode_filename)\n",
    "\n",
    "def write_raw_zipcode_files(zip_filepath):\n",
    "    shape_filepath = zip_filepath.replace('.zip', '.shp')\n",
    "    with fiona.open(shape_filepath, 'r') as FILE:\n",
    "        FEATURE_SIZE = len(FILE)\n",
    "\n",
    "        if FEATURE_SIZE == count_files(RAW_ZIPCODES_DIRPATH):\n",
    "            print(f'raw zipcode files already written: {FEATURE_SIZE} files')\n",
    "            return None\n",
    "        \n",
    "        ZCTA5_KEY = None\n",
    "        for COUNT, FEATURE in enumerate(FILE, start=1):\n",
    "            ZCTA5_KEY = ZCTA5_KEY or next((key for key in dict(FEATURE.properties).keys() if key.startswith('ZCTA5')), None)\n",
    "            zipcode = FEATURE.properties[ZCTA5_KEY]\n",
    "            PROGRESS_BAR = progress_bar(COUNT, FEATURE_SIZE, 'files')\n",
    "            print(f'\\rWriting Zipcode `{zipcode}`: {PROGRESS_BAR}', end='')\n",
    "\n",
    "            zipcode_filepath = get_zipcode_filepath(zipcode + RAW_JSON_EXT)\n",
    "            zipcode_json = {\n",
    "                'type': 'Feature',\n",
    "                'properties': dict(FEATURE.properties),\n",
    "                'geometry': dict(FEATURE.geometry),\n",
    "            }\n",
    "\n",
    "            with open(zipcode_filepath, 'w') as ZIPCODE_FILE:\n",
    "                json.dump(zipcode_json, ZIPCODE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = get_download_url()\n",
    "zip_filepath = download_zip_file(download_url)\n",
    "unzip_downloaded_file(zip_filepath)\n",
    "make_zipcode_directory(RAW_ZIPCODES_DIRPATH)\n",
    "write_raw_zipcode_files(zip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Simplify Raw Zipcodes\n",
    "    - Make Zipcodes Directory\n",
    "    - Simplify Raw Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "ANGLE_THRESHOLD = 1.0\n",
    "PRECISION = 0.0001\n",
    "SIGFIGS = min(len(f'{PRECISION:.7f}'.rstrip('0').split('.')[1]), 6) # restricts significant decimal figures equal to that of PRECISION\n",
    "GEOJSON_EXT = '.geojson'\n",
    "\n",
    "# helpers\n",
    "def get_geometry_from_filepath(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.loads(file.read())\n",
    "        return shape(data['geometry'])\n",
    "\n",
    "def get_coordinates_from_geometry(geometry):\n",
    "    return json.loads(json.dumps(mapping(geometry)['coordinates']))\n",
    "\n",
    "def prune_coordinates(coordinates):\n",
    "\n",
    "    def triplets(x): # generates triplets of sequentially adjacent elements with wrap-around\n",
    "        return zip(*[x[i:] + x[:i] for i in range(-1, 2)])\n",
    "\n",
    "    def angle(points): # returns the angle in degrees measured offset from perpendicular [0, 90]\n",
    "        a, b, c = points # unpack points\n",
    "        V, W = np.array(b) - np.array(a), np.array(b) - np.array(c) # compute vectors\n",
    "        m = np.linalg.norm(V) * np.linalg.norm(W) # compute magnitude\n",
    "        return 90.0 if m == 0 else abs(90.0 - np.arccos(np.clip(np.dot(V, W) / m, -1.0, 1.0)) * 180.0 / np.pi) # compute angle (degrees)\n",
    "\n",
    "    n = len(coordinates); angles = [angle(points) for points in triplets(coordinates)]\n",
    "    while n > 2: # stop if less than 3 points\n",
    "        sorted_angles = sorted(enumerate(angles), key=lambda x: x[1]) # assign an ordered index and sort by angle size\n",
    "        i, max_angle = sorted_angles[-1] # get max angle and index\n",
    "        if max_angle < 90.0 - ANGLE_THRESHOLD: break # stop if max angle does not exceed angle threshold\n",
    "        coordinates.pop(i); angles.pop(i); n -= 1 # update angles adjacent to removed index\n",
    "        prev = (i - 1) % n; next = i % n # update angles adjacent to removed index\n",
    "        angles[prev] = angle([coordinates[prev - 1], coordinates[prev], coordinates[next]])\n",
    "        angles[next] = angle([coordinates[prev], coordinates[next], coordinates[(next + 1) % n]])\n",
    "    return coordinates if len(coordinates) > 2 else []\n",
    "\n",
    "def snap_to_grid(point):\n",
    "\n",
    "    def grid_mod(x, y): # returns true if x >= y/2 (with modulus clipping)\n",
    "        return x % (2 * y) > y \n",
    "    \n",
    "    def point_line(x, y, m, b): # result is positive if point (x, y) is above linear equation y = m * x + b\n",
    "        return y - x * m - b\n",
    "\n",
    "    def adjusted_point(x_min, y_min, t, bool): # snaps point to grid by rounding based on proximity to PRECISION\n",
    "        t_bool = t > 0\n",
    "        return [\n",
    "            round(x_min + PRECISION * ((t_bool + bool) % 2), SIGFIGS),\n",
    "            round(y_min + PRECISION * t_bool, SIGFIGS),\n",
    "        ]\n",
    "\n",
    "    Px_MOD, Py_MOD = point[0] % PRECISION, point[1] % PRECISION # determine relative position using modulus of point x and y\n",
    "    X_MIN, Y_MIN = point[0] - Px_MOD, point[1] - Py_MOD # compute lower X and Y\n",
    "    BOOL = (grid_mod(point[0], PRECISION) + grid_mod(point[1], PRECISION)) % 2 # compute oddity\n",
    "    m, b = BOOL * 2 - 1, PRECISION * (1 - BOOL) # compute slopy and y-intercept\n",
    "    t = point_line(Px_MOD, Py_MOD, m, b)\n",
    "    if t * 8 ** .5 > PRECISION: # zone classification for point in grid\n",
    "        return adjusted_point(X_MIN, Y_MIN, t, BOOL)\n",
    "    t = point_line(Px_MOD, Py_MOD, -m, PRECISION - b)\n",
    "    return adjusted_point(X_MIN, Y_MIN, t, BOOL)\n",
    "\n",
    "def polify(geoms):\n",
    "    result = []\n",
    "    for geom in geoms:\n",
    "        if geom.geom_type.endswith('Polygon'):\n",
    "            result.append(geom)\n",
    "        elif geom.geom_type == 'LinearRing':\n",
    "            result.append(Polygon(geom))\n",
    "    return result\n",
    "\n",
    "def coordinates_need_further_simplification(arr):\n",
    "\n",
    "    def flatten_array(arr):\n",
    "        if not isinstance(arr, list):\n",
    "            return [arr]\n",
    "        flattened = []\n",
    "        for item in arr:\n",
    "            flattened.extend(flatten_array(item))\n",
    "        return flattened\n",
    "\n",
    "    def num_decimals(value):\n",
    "        return len(str(value).split('.')[1]) if '.' in str(value) else 0\n",
    "\n",
    "    return any(num_decimals(num) > SIGFIGS for num in flatten_array(arr))\n",
    "\n",
    "def union(geometries, exit=False):\n",
    "    result = geopandas.GeoDataFrame(geometry=geometries).union_all()\n",
    "    if result.geom_type == 'GeometryCollection':\n",
    "        return union(polify(result.geoms))\n",
    "    if not result.is_valid:\n",
    "        return simplify(make_valid(result))\n",
    "    coords = get_coordinates_from_geometry(result)\n",
    "    if not exit and coordinates_need_further_simplification(coords):\n",
    "        return simplify(result, exit=True)\n",
    "    return result\n",
    "\n",
    "def force_multipolygon(geometry):\n",
    "    return geometry if geometry.geom_type == 'MultiPolygon' else MultiPolygon([geometry])\n",
    "\n",
    "def simplify(geometry, exit=False):\n",
    "    new_geometry = []\n",
    "    geometry_coordinates = get_coordinates_from_geometry(force_multipolygon(geometry))\n",
    "    for polygon in geometry_coordinates:\n",
    "        new_polygon = []\n",
    "        for coordinates in polygon:\n",
    "            new_coordinates = prune_coordinates([snap_to_grid(point) for point in prune_coordinates(coordinates)])\n",
    "            if not new_coordinates: continue\n",
    "            new_polygon.append(new_coordinates)\n",
    "        if not new_polygon: continue\n",
    "        outer, *inner = new_polygon\n",
    "        new_polygon = Polygon(outer, inner)\n",
    "        if not new_polygon.is_valid:\n",
    "            new_polygon = make_valid(new_polygon)\n",
    "        new_geometry.append(new_polygon)\n",
    "    return union(new_geometry, exit)\n",
    "\n",
    "def generate_geojson(geometry, key_name, value):\n",
    "    if not geometry.geom_type.endswith('Polygon'):\n",
    "        raise Exception('Geometry Type not Polygon or MultiPolygon')\n",
    "    return {\n",
    "        'type': 'Feature',\n",
    "        'properties': {\n",
    "            key_name: value,\n",
    "            'bounds': geometry.bounds,\n",
    "        },\n",
    "        'geometry': {\n",
    "            'type': geometry.geom_type,\n",
    "            'coordinates': get_coordinates_from_geometry(geometry),\n",
    "        },\n",
    "    }\n",
    "\n",
    "def simplify_raw_zipcodes():\n",
    "    TOTAL_FILES = count_files(RAW_ZIPCODES_DIRPATH)\n",
    "\n",
    "    CONVERSION_RATE = count_files(ZIPCODES_DIRPATH) / TOTAL_FILES\n",
    "    if CONVERSION_RATE > .9:\n",
    "        print(f'zipcode files already written: {TOTAL_FILES} raw | {count_files(ZIPCODES_DIRPATH)} simplified | {CONVERSION_RATE * 100:.1f}% conversion rate')\n",
    "        return None\n",
    "\n",
    "    make_zipcode_directory(ZIPCODES_DIRPATH)\n",
    "    COUNT = 0\n",
    "    for raw_zipcode_dir in os.listdir(RAW_ZIPCODES_DIRPATH):\n",
    "        raw_zipcode_dirpath = os.path.join(RAW_ZIPCODES_DIRPATH, raw_zipcode_dir)\n",
    "        for raw_zipcode_filename in os.listdir(raw_zipcode_dirpath):\n",
    "            zipcode = raw_zipcode_filename[:5]\n",
    "\n",
    "            COUNT += 1\n",
    "            PROGRESS_BAR = progress_bar(COUNT, TOTAL_FILES, 'files')\n",
    "            print(f'\\rSimplifying Zipcode `{zipcode}`: {PROGRESS_BAR}', end='')\n",
    "\n",
    "            new_zipcode_filepath = get_zipcode_filepath(zipcode + GEOJSON_EXT)\n",
    "            if os.path.exists(new_zipcode_filepath) and os.path.getsize(new_zipcode_filepath) > 0: continue # file already exists\n",
    "            raw_geometry = get_geometry_from_filepath(get_zipcode_filepath(raw_zipcode_filename))\n",
    "            new_geojson = generate_geojson(simplify(raw_geometry), 'zipcode', zipcode)\n",
    "\n",
    "            with open(new_zipcode_filepath, 'w') as file:\n",
    "                json.dump(new_geojson, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_raw_zipcodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Merge Zipcodes and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_holes(geometry):\n",
    "    if isinstance(geometry, Polygon):\n",
    "        return Polygon(geometry.exterior)\n",
    "    if isinstance(geometry, MultiPolygon):\n",
    "        polygons = [Polygon(p.exterior) for p in geometry.geoms]\n",
    "        return MultiPolygon(polygons) if len(polygons) > 1 else polygons[0]\n",
    "    else:\n",
    "        raise TypeError('geometry must be a Polygon or MultiPolygon')\n",
    "\n",
    "def merge_geometry_filepaths_to_file(geometry_filepaths, new_filepath, property_name, property_value, no_holes=True):\n",
    "    if os.path.exists(new_filepath) and os.path.getsize(new_filepath) > 0:\n",
    "        return # file already exists\n",
    "    geometries = []\n",
    "    for filepath in geometry_filepaths:\n",
    "        try: geometries.append(get_geometry_from_filepath(filepath))\n",
    "        except: pass\n",
    "    if geometries:\n",
    "        merged_geometry = union(geometries)\n",
    "        if no_holes:\n",
    "            merged_geometry = remove_holes(merged_geometry)\n",
    "        if geojson := generate_geojson(merged_geometry, property_name, property_value):\n",
    "            with open(new_filepath, 'w') as file:\n",
    "                json.dump(geojson, file)\n",
    "\n",
    "def get_center(geojson):\n",
    "    min_x, min_y, max_x, max_y = geojson['properties']['bounds']\n",
    "    center = [(min_y + max_y) / 2, (min_x + max_x) / 2]\n",
    "    return center\n",
    "\n",
    "def get_zoom(geojson):\n",
    "    min_x, _, max_x, _ = geojson['properties']['bounds']\n",
    "    diff = (max_x - min_x) % 360\n",
    "    return np.floor(10 - np.log2(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merged geometry file\n",
    "SELECTED_ZIPCODES = [f'{zipcode:05d}' for zipcode in range (1001, 1101)]\n",
    "GEOMETRY_FILEPATHS = [get_zipcode_filepath(ZIPCODE + GEOJSON_EXT) for ZIPCODE in SELECTED_ZIPCODES]\n",
    "OUTPUT_FILENAME = 'merged_geometry.test'\n",
    "OUTPUT_FILEPATH = OUTPUT_FILENAME + GEOJSON_EXT\n",
    "os.path.exists(OUTPUT_FILEPATH) and os.remove(OUTPUT_FILEPATH)\n",
    "merge_geometry_filepaths_to_file(GEOMETRY_FILEPATHS, OUTPUT_FILEPATH, 'Region', OUTPUT_FILENAME)\n",
    "\n",
    "# initialize map\n",
    "with open(OUTPUT_FILEPATH, 'r') as file:\n",
    "    region_geojson = json.load(file)\n",
    "map = folium.Map(\n",
    "    location=get_center(region_geojson),\n",
    "    zoom_start=get_zoom(region_geojson),\n",
    ")\n",
    "\n",
    "# add individual zipcodes with their labels\n",
    "for GEOMETRY_FILEPATH in GEOMETRY_FILEPATHS:\n",
    "    try:\n",
    "        with open(GEOMETRY_FILEPATH, 'r') as file:\n",
    "            geojson = json.load(file)\n",
    "        folium.GeoJson(\n",
    "            geojson,\n",
    "            style_function=lambda feature: {\n",
    "                'weight': 1,\n",
    "                'color': 'red',\n",
    "                'opacity': 1.0,\n",
    "                'fillColor': 'blue',\n",
    "                'fillOpacity': 0.2,\n",
    "            },\n",
    "        ).add_to(map)\n",
    "        folium.Marker(\n",
    "            location=get_center(geojson),\n",
    "            icon=folium.DivIcon(\n",
    "                html=f'<div style=\"font-size: 12px; color: black; font-weight: bold;\">{geojson['properties']['zipcode']}</div>'\n",
    "            ),\n",
    "        ).add_to(map)\n",
    "    except: pass\n",
    "\n",
    "# add merged region border on top\n",
    "folium.GeoJson(\n",
    "    region_geojson,\n",
    "    style_function=lambda feature: {\n",
    "        'weight': 3,\n",
    "        'color': 'blue',\n",
    "        'opacity': .5,\n",
    "        'fillOpacity': 0.0,\n",
    "    }\n",
    ").add_to(map)\n",
    "\n",
    "map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
